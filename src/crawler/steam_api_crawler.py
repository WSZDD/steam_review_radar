import requests
import pandas as pd
import numpy as np
from src.analysis.sentiment_analysis import SentimentAnalyzer
try:
    analyzer = SentimentAnalyzer()
except Exception as e:
    print(f"CRITICAL: æ— æ³•åˆå§‹åŒ– SentimentAnalyzer. {e}")
    analyzer = None

def fetch_game_reviews(appid, language="schinese", num_reviews=50, review_type="all"):
    """
    è·å– Steam æ¸¸æˆè¯„è®ºï¼Œè¿”å› DataFrame åŒ…å«ï¼š
    author_nameã€author_avatarã€contentã€voted_up
    """
    url = (
        f"https://store.steampowered.com/appreviews/{appid}"
        f"?json=1"
        f"&language={language}"
        f"&filter=all"                     # âœ… æŒ‰â€œæœ‰å¸®åŠ©åº¦â€æ’åº
        f"&review_type={review_type}"
        f"&day_range=9223372036854775807"  # âœ… å…¨æ—¶é—´èŒƒå›´
        f"&num_per_page={num_reviews}"
        f"&cursor=*"
    )
    params_summary = (
        f"https://store.steampowered.com/appreviews/{appid}"
        f"?json=1"
        f"&language=all"
        f"&review_type=all"
        f"&num_per_page=0"
        f"&cursor=*"
    )
    print(f"ğŸ•·ï¸ [Crawler] Fetching: {url}")
    res = requests.get(url)
    data = res.json()
    reviews = data.get("reviews", [])

    if not reviews:
        # è¿”å›åŒ…å«æ–°åˆ—çš„ç©º DataFrame
        cols = ["author_name", "author_avatar", "content", "voted_up", 
                "score_gameplay", "score_visuals", "score_story", "score_opt", "score_value"]
        return pd.DataFrame(columns=cols), {}

    # 1. æ„é€ åŸºç¡€ DataFrame
    df = pd.DataFrame([{
        "author_name": r["author"].get("steamid", "åŒ¿å"),
        "author_avatar": r["author"].get("avatar", ""),
        "content": r.get("review", ""),
        "voted_up": r.get("voted_up", False),
        "appid": appid,
        "playtime_at_review": r["author"].get("playtime_at_review", 0),
        "votes_up": r.get("votes_up", 0),
        "timestamp_created": r.get("timestamp_created", 0)
    } for r in reviews])

    # 2. æ‰§è¡Œå¤šç»´æƒ…æ„Ÿåˆ†æ
    if analyzer:
        print(f"ğŸ¤– [Crawler] æ­£åœ¨å¯¹ {len(df)} æ¡è¯„è®ºè¿›è¡Œå¤šç»´é›·è¾¾åˆ†æ...")
        
        score_dicts = analyzer.analyze_batch(df['content'])
        
        # è½¬æ¢ä¸º DataFrame å¹¶åˆå¹¶
        df_scores = pd.DataFrame(score_dicts)
        df = pd.concat([df, df_scores], axis=1)
        
        print("âœ… [Crawler] å¤šç»´åˆ†æå®Œæˆã€‚")
    else:
        # å¡«å……é»˜è®¤å€¼
        for col in ["score_gameplay", "score_visuals", "score_story", "score_opt", "score_value"]:
            df[col] = 0.5

    # ... (Summary è·å–éƒ¨åˆ†ä¿æŒä¸å˜) ...
    res_summary = requests.get(params_summary)
    summary = {}
    if res_summary.status_code == 200:
        summary_data = res_summary.json()
        if summary_data.get("success") == 1:
            summary = summary_data.get("query_summary", {})

    return df, summary


def get_appid_by_name(game_name):
    """
    æ ¹æ®æ¸¸æˆåä» Steam æœç´¢æ¥å£è·å– appidã€çœŸå®æ¸¸æˆåã€å°é¢å›¾ã€æ¸¸æˆè¯¦æƒ…
    """
    search_url = "https://store.steampowered.com/api/storesearch"
    params = {"term": game_name, "l": "schinese", "cc": "CN"}
    res = requests.get(search_url, params=params)

    data = res.json()

    if not data.get("items"):
        return None, None, None, None

    game = data["items"][0]
    appid = game["id"]
    game_real_name = game["name"]
    img_url = game["tiny_image"]

    # ====== è·å–æ¸¸æˆè¯¦ç»†ä¿¡æ¯ ======
    detail_url = f"https://store.steampowered.com/api/appdetails?appids={appid}&l=schinese&cc=CN"
    detail_res = requests.get(detail_url).json()
    detail = detail_res[str(appid)]["data"]

    info = {
        "name": detail.get("name"),
        "release_date": detail.get("release_date", {}).get("date", "æœªçŸ¥"),
        "price": detail.get("price_overview", {}).get("final_formatted", "å…è´¹") if detail.get("is_free") == False else "å…è´¹",
        "developer": ", ".join(detail.get("developers", [])) if detail.get("developers") else "æœªçŸ¥",
        "publisher": ", ".join(detail.get("publishers", [])) if detail.get("publishers") else "æœªçŸ¥",
        "short_description": detail.get("short_description", "æš‚æ— ç®€ä»‹"),
        "header_image": detail.get("header_image", img_url),
    }

    return appid, game_real_name, img_url, info

# --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ›¿æ¢è¿™ä¸ªå‡½æ•° ---
def fetch_data_for_timeseries(appid, max_pages=10):
    """
    ä¸“é—¨ä¸ºæ—¶åºåˆ†æçˆ¬å–å¤§é‡ï¼ˆæœ€å¤š 1000 æ¡ï¼‰è¯„è®ºã€‚
    ã€å·²ä¿®æ”¹ã€‘æŒ‰æœˆç»Ÿè®¡å¥½è¯„æ•°å’Œå·®è¯„æ•°ã€‚
    """
    print(f"ğŸ”¬ [TimeSeries] å¼€å§‹ä¸º {appid} çˆ¬å–æ—¶åºæ•°æ® (æœ€å¤š {max_pages} é¡µ)...")
    all_reviews_data = []
    next_cursor = "*" 
    
    for page in range(max_pages):
        if not next_cursor:
            break 
        
        print(f"  ... æ­£åœ¨çˆ¬å–æ—¶åºæ•°æ®ç¬¬ {page+1}/{max_pages} é¡µ")
        
        params = {
            "json": 1,
            "language": "all", 
            "filter": "all",  # æŒ‰â€œæœ‰å¸®åŠ©â€æ’åºï¼Œè·å–å…¨æ—¶é—´è·¨åº¦
            "day_range": "9223372036854775807",
            "num_per_page": 1000,
            "cursor": next_cursor 
        }
        
        try:
            res = requests.get(f"https://store.steampowered.com/appreviews/{appid}", params=params, timeout=10)
            res.raise_for_status()
            data = res.json()
            
            if data.get("success") != 1 or "reviews" not in data:
                break
                
            for review in data["reviews"]:
                # --- ã€ä¿®æ”¹ã€‘ä¸å†éœ€è¦æƒ…æ„Ÿåˆ†æ ---
                all_reviews_data.append({
                    "timestamp_created": review.get("timestamp_created", 0),
                    "voted_up": review.get("voted_up", False) # åªéœ€è¦å¥½è¯„/å·®è¯„
                })
            
            next_cursor = data.get("cursor") 
            
        except Exception as e:
            print(f"âŒ [TimeSeries] çˆ¬å–åˆ†é¡µæ—¶å‡ºé”™: {e}")
            break
    
    print(f"âœ… [TimeSeries] çˆ¬å–å®Œæ¯•ï¼Œå…± {len(all_reviews_data)} æ¡è¯„è®ºã€‚")
    
    if not all_reviews_data:
        return {} # è¿”å›ç©ºå­—å…¸

    # --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨ Pandas è¿›è¡Œé«˜çº§åˆ†ç»„ç»Ÿè®¡ ---
    df_time = pd.DataFrame(all_reviews_data)
    df_time['timestamp'] = pd.to_datetime(df_time['timestamp_created'], unit='s')
    df_time = df_time.set_index('timestamp')

    # 1. æŒ‰ 'voted_up' (True/False) åˆ†ç»„
    # 2. æŒ‰æœˆ ('M') é‡é‡‡æ ·
    # 3. ç»Ÿè®¡æ¯ç»„çš„æ•°é‡ (.size())
    # 4. å°† 'voted_up' (True/False) ä½œä¸ºåˆ—å±•å¼€ (.unstack())
    counts_over_time = df_time.groupby('voted_up').resample('M').size().unstack(level=0, fill_value=0)
    
    # 5. é‡å‘½ååˆ—
    counts_over_time = counts_over_time.rename(columns={True: 'positive', False: 'negative'})
    
    # 6. ç¡®ä¿ä¸¤åˆ—éƒ½å­˜åœ¨
    if 'positive' not in counts_over_time:
        counts_over_time['positive'] = 0
    if 'negative' not in counts_over_time:
        counts_over_time['negative'] = 0

    # 7. æ’åº
    counts_over_time = counts_over_time.sort_index()

    # 8. æ ¼å¼åŒ–ä¸º ECharts éœ€è¦çš„æ•°æ®ç»“æ„
    time_series_data = {
        'dates': [date.strftime('%Y-%m') for date in counts_over_time.index],
        'positive_counts': counts_over_time['positive'].tolist(),
        'negative_counts': counts_over_time['negative'].tolist()
    }
    return time_series_data
# --- ã€æ›¿æ¢ç»“æŸã€‘ ---